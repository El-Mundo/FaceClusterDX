# FaceClusterDX
A face-clustering toolkit for MacOS (Silicon)



## Intro Panel

<img width="320" alt="Screenshot 2024-12-14 at 00 03 53" src="https://github.com/user-attachments/assets/f176d76b-8c64-40be-bd78-d6b200eb4873" />

The intro panel gives quick access to two options: [**load video**](#load-video) or [**load project**](#load-project).

### Load Project
A project is a file in **.fcproject** format generated by this application, which resumes the face-clustering networks created and edited by the user. A .fcproject file is manually generated by saving a project in the editor.

### Load Video
To start a new project, the user will have to select a video with the "load video" option. Directly supported formats are **.mp4** and **.mov**, but technically all formats compatible with the **AVFoundation** utility should be usable (tweaking might be necessary for esoteric formats, though).

<img width="320" alt="Screenshot 2024-12-14 at 00 12 14" src="https://github.com/user-attachments/assets/3e92147d-ee6f-4dc4-9e5c-c5ac2cc735bd" />

Successful decoding of a video file will direct the user to the import setting page. It gives the user two import settings: **frame extraction interval** ("analyze every") and **frame scaling**. **Frame extraction interval** is used to reduce the number of the frames used for face recognition, which improves stability for large video processing. It also supports two units for deciding the interval: second and frame. **Frame scaling** decides if the analyzed frames should be scaled down to provide further acceleration.



## Data Structure

This application stores all faces as objects with multiple **attributes**. Seven basic attributes are generated upon the face's being detected. These are frame index (integer), face box (4D vector), confidence (decimal), face rotation (3D vector generated by Apple's face API), Path (string, the relative path where the face is stored), cluster (string), and position (point variable).

All attributes align with one of the six types: integer, decimal, integer vector, decimal vector, string, and point. In addition to the basic attributes, the user can add new attributes to a network or remove the added attributes (basic attributes cannot be removed, but "position" can be replaced by other point attributes). The point type is a special type that is used for face clustering. In the editor's **Overview panel**, the user can decide an attribute of point type to be the **"display positioning attribute"**. This action will make the faces in the Network panel rearranged according to the new position attribute, and the distances between faces calculated based on the positioning attribute are used for dividing all faces into clusters.


## Editor

After loading a previous project or creating a new project with a video, the user will be navigated to the editor. The editor provides five panels for manipulating and interpreting the statistics generated by face recognition and clustering, including [**Network**](#network), [**Frames**](#Fframes), [**Overview**](#overview), [**Project**](#project), [**Timeline**](#timeline), plus [**a bottom toolbar**](#toolbar).

### Network

<img width="480" alt="Screenshot 2024-12-14 at 00 54 04" src="https://github.com/user-attachments/assets/4ac20390-c8a2-4027-ab59-65d3fa8f5128" />

The Network panel is the default view of the editor. It provides a GUI-empowered interface for editing and finetuning the results of face clustering. In this page all faces are positioned based on the point attribute set as the **"display positioning attribute"**, while editing occurring in this panel is directly saved to that attribute's values.

The user can switch between two modes using **the Preview/Edit Button** in the toolbar. In the **Preview** mode, the button writes "Edit", and the user can drag the canvas to navigate in the network preview. Mouse wheel is used to zoom in/out the canvas. **The Cluster button** shown in this mode allows the user to regenerate all clusters based on the current positions of all faces and a given distance. In the **Edit** mode, however, dragging will allow the user to move the positions of faces. The Cluster button is replaced with a slider that determines the range of dragging. if the slider is at the minimal value, only one face can be dragged at once, but if a higher range is picked, multiple faces within the cursor can be relocated together.

In both modes, the user can **deactivate** certain faces by right-clicking it. Deactivated faces are not included in data analysis and clustering but still stored within the network and can be recovered by another right-click in the Network panel.

There are also three modes for displaying the cluster results: **none**, **lines**, and **polygons**. The polygon mode is used by default, but it has an issue that when there are only two faces in a cluster, the cluster cannot be displayed. The lines mode addresses this issue by drawing lines between all pairs of faces in a cluster.

### Frames

<img width="480" alt="Screenshot 2024-12-14 at 00 55 05" src="https://github.com/user-attachments/assets/f23dd9de-3cba-4d29-9ace-e65eb1448b33" />

The Frames panel is used to control the results of facial recognition at frame-level accuracy.

The user can click a frame in the grid on the left to edit the faces in this frame. The buttons on top of the grid also allows the user to delete or import single frames as images.

In the panel on the right, the user could re-detect faces for the chosen frame. The user can also select a face in the frame by clicking the boxes on the image preview or the columns in the list below. They can delete the selected face or look at it in details by selecting a "aligning display" mode. This image shows the three modes of aligning display: **landmark lines** (left), **landmark points** (middle), and **aligned face** (right):

<img width="600" alt="Screenshot 2024-12-14 at 01 04 38" src="https://github.com/user-attachments/assets/69e2ee0e-4ad8-4a13-af7c-16df50cc8172" />

The difference between aligned face and the original picture is mild here because the shown image is frontal.

### Overview



### Project



### Timeline



### Toolbar



## Misc

### References

| Referenced Projects | Content |
|---------------------|---------|
| [Facenet](https://github.com/davidsandberg/facenet/blob/master/LICENSE.md) | Facial attribute recognition model (Facenet512) |
| [MTCNN-Caffe](https://github.com/CongWeilin/mtcnn-caffe) | Face alignment models (MTCNN) |
| [Swift-TSNE](https://github.com/emannuelOC/swift-tsne) | T-SNE implemented for Swift (CPU) | 



### Know Issues

Manually adding jpg and jpeg files with the same file name will result in unexpectable errors with face image identification. Using the import utility in the Frame view will avoid such issue by forcing all jpeg files to be imported as jpg format.

### To-dos

1. Improve T-SNE implement
2. Clean unused codes
3. Improve the stability of multi-network project editing
